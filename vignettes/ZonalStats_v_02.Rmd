---
title: "Zonal Averages"
author: "jmj00@ucsb.edu"
date: "1/10/2019"
output:
   html_document:
    toc: true
    theme: journal
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=8.5, 
  fig.height=5
)

options(scipen = 9999)

source("../inProgress/climateR_zonalStat2.R")
library(sf)
library(spex)
devtools::load_all(".")
```

## Introduction

In R, as in many programming and GIS interfaces, *polygonizing*, *gathering data* and *computing zonal averages* are frequent, complicated, and time-consuming processes. This document shows how this process can be carried out, for climate data, using the [`climateR`](https://github.com/mikejohnson51/climateR) package. 

In principle, calculating zonal statistics requires a gridded data source (eg Daily precipitation) and an overlaying polygon set (eg state counties or watershed boundaries) over which to aggregate the gridded data. This document walks through a few examples, including (1) getting spatial boundary and meteorological data (2) polygonizing the raster meteorological data and (3) calculating zonal averages over the input polygon features. 

This document outlines three examples. The first illustrates the concepts and functions being used to compute county average rainfall over a seven day period in October 2018. The second will look at the average October solar radiation for all HUC12 units in Santa Barbara County, and the third focuses on the scalability of these methods by examining the average county-based rainfall over the south eastern USA coast through the life-span of Hurricane Florence. 

Simular/Referenced Work:

1. [AOI](https://github.com/mikejohnson51/AOI)
2. [areal](https://github.com/slu-openGIS/areal)
3. [climateR](https://github.com/mikejohnson51/climateR)
4. [HydroData](https://github.com/mikejohnson51/climateR)
5. [intersectr](https://github.com/dblodgett-usgs/intersectr)

## Get Polygon Data

Here we get the spatial data for North Carolina Counties using the [AOI](https://github.com/mikejohnson51/AOI) package (a dependency of climateR).

```{r}
nc = getAOI(state = c('NC'), county = 'all', sf = T)

plot(nc[,"countyfp"],  main = "North Carolina Counties", col = sf.colors(100))
```

## Get Climate Raster Data

With an AOI (eg North Carolina Counties), `climateR` can be used to extract gridded meteorological data from a specified source, given parameter, and time span. In this example we will get PRISM precipitation data from October 11-16, 2018. 

```{r}
## Fix climateR to accept sf objects!
(prcp.nc = getPRISM(as_Spatial(nc), "prcp", startDate = "2018-10-11", endDate = "2018-10-16")[[1]])

rasterVis::levelplot(prcp.nc[[2]], main = "October 12, 2018 PRISM Precipitation", margin = F)
```

## Faster Polygonizing

One common task (and one central to calculating zonal statistics) is the need to polgonize rasters (similar to `raster::rasterToPolygon`).

```{r}
system.time({
(p = raster::rasterToPolygons(prcp.nc) %>% st_as_sf())
})

head(p)
```

While `raster::rasterToPolygon` almost gets us what we need it is relatively slow, doesn't scale well to large regions and doesn't identify extracted values by a the grid cell ID.

The climateR `makeGrid` function expedites this process by making use of the base raster meta information and the core features of the sf package. Additionally, `makeGrid` appends grid cell IDs to the sf object (counting downward column-wise). This feature is critical to aggregating data across space and time!

```{r}
system.time({
grid = make_grid2(prcp.nc)
})

head(grid)
plot(grid[,"X2018.10.12"], border = NA)
```

## Get Weights of Associated polygons

With a polygon feature set (North Carolina Counties) and a polygonized raster set with grid cell IDs (PRISM grid), we need to calculate the percentage of each grid cell that falls within each polygon feature. 

To do this the climateR `get_weights` function. provides a wrapper around the [`areal`](https://github.com/slu-openGIS/areal) package and was loosely adapted from the fantastic [intersectr](https://github.com/dblodgett-usgs/intersectr) package by [Dave Blodgett] (https://www.usgs.gov/staff-profiles/david-l-blodgett?qt-staff_profile_science_products=3#qt-staff_profile_science_products). The inputs needed are the polygonized grid, the polygon feature set, and the attribute over which to weight the cells. In this case we are using the county FIP codes:

```{r}
# Here, 'countfp' is the polygon ID (attribute) we want to aggregate by
system.time({
  w = get_weights(grid, nc, "countyfp")
})

head(w[!is.na(w$countyfp),])
```

## Execute Zonal Average

With a grid, feature polygon set, and a cell-by-cell weighting scheme we can quickly aggregate the zonal mean for each polygon feature (county) 

```{r}
system.time({
  z = zonal_stats1(grid, nc, w)
})

plot(z[, grep("X2018", names(z))], border = NA)
```

```{r}
{plot(grid$geometry, lwd = .2, main = "PRISM October 12, 2018")
plot(grid["X2018.10.12"], border = NA, add = TRUE)
plot(z["X2018.10.12"], add = TRUE)}

```


## Santa Barbara County Watersheds Mean Solar Radiation (GridMet)

With a clear understanding of the `climateR` zonal weighting process, lets look at an example that provides both a sanity check of the results and an example of ingesting watershed boundary data via the `HydroData` package. In this example we will calculate the mean solar radiation hitting HUC12 units in Santa Barbara county. To do this we will use `HydroData::findWBD` to read in all HUC12 features for Santa Barbara County, `climateR::getGridMet` to read in solar radiation data from gridMet for the month of October and the `climateR` zonal average method. 

We expect to see a clear variation running nearly east to west across the county caused by the Santa Ynez Mountain range. 

```{r}

system.time({

# Define AOI, and collect HUC12 data
huc = getAOI(state = "CA", county = "Santa Barbara") %>% HydroData::findWBD(level = 12)

# Seperate HUC12 data from list
huc = huc$huc12

# Get Solar radaition data
rad = getGridMET(huc, "srad", startDate = "2018-10-01", endDate = "2018-10-31")[[1]]

# Polygonize, weight and aggregate
sb.grid = make_grid2(rad)

sb.weights = get_weights(sb.grid, huc, 'HUC12')
sb.rad.zones = zonal_stats1(sb.grid, huc, sb.weights)
})

```

```{r}
# Plot first 10 day raster data
rasterVis::levelplot(rad[[1:10]])

# Plot first 10 day HUC12 values
plot(sb.rad.zones[,grep("X2018", names(sb.rad.zones))], border = NA, max.plot = 10)

# Determine the October Average 
sb.rad.zones$oct.avg = data.frame(sb.rad.zones) %>% 
  dplyr::select(grep("X2018", names(sb.rad.zones))) %>% 
  rowMeans() %>% 
  round(2)

# Plot
plot(sb.rad.zones[,"oct.avg"], border = NA, main = "October 2018 Average Radiation")
```
For our sanity check we see that the higher average radiation occurs along the central east/west mountain corridor with lower radiation values along the coasts.  


## Scaleing it up: Hurricane Florence

The last test of this method is to see how well it can handle large data requests both in time and space. To test this we want to explore the total average rainfall recieved by all counies in South Carolina, North Carolina, Virgina, West Virgina, and Georgia during hurricane Florence (August 31 - Sep 19 2018):

```{r}
xx = system.time({
AOI = getAOI(state = c("SC", "NC", "VA", "WV", "GA"), county = "all")

hurr = getPRISM(AOI, "prcp", startDate = "2018-08-31", endDate = "2018-09-19")[[1]]

hurr.grid = make_grid2(hurr)

w3 = get_weights(hurr.grid, AOI, 'geoid')
z3 = zonal_stats(hurr, AOI, w3)

})


par(mfrow=c(1,3))
plot(hurr.grid["X2018.09.15"], border = NA, key.pos = NULL, reset = FALSE)
plot(hurr.grid["X2018.09.15"], border = NA, key.pos = NULL, reset = FALSE)
plot(z3["geometry"], border = 'black', lwd = 1, add = T, reset = FALSE)
plot(z3["X2018.09.15"], border = 'white', lwd = .1, key.pos = NULL, reset = FALSE)
```


In total `r dim(hurr)[3]`  days worth of precipitation data was download and averaged to the county level in `r xx[3]` seconds. Finally, we sum all daily values to get the total average rainfall experienced by each county:

```{r}
z3$hurricane = data.frame(z3) %>% 
  dplyr::select(grep("X2018", names(z3))) %>% 
  rowSums() %>% 
  round(2)

plot(z3[,"hurricane"], border = "transparent", main = "Hurricane Florence: Aug-31-18 - Sep-19-18")
```

## Core Functions for Reference

```{r}

make_grid2 = function(r){
  
  grd_lrg <- spex::polygonize(r, na.rm = F)
  
  y.dim = dim(r)[1]
  x.dim = dim(r)[2]

  grd_lrg['grid_ids'] <- as.vector(t(matrix(c(1:(x.dim*y.dim)),
                                            nrow = y.dim,
                                            ncol = x.dim,
                                            byrow = F)))
  
  return(grd_lrg)
}

get_weights = function(grid, poly, abb = NULL){

  if(is.null(abb)){ abb = names(poly)[1]}

  if(!AOI::checkClass(poly, "sf")) { poly = sf::st_as_sf(poly) }

  if(st_crs(poly) != st_crs(grid)) { poly  = st_transform(poly, st_crs(grid)) }

  if(abb %in% names(poly)){ poly = poly[,abb] } else { stop(paste(abb, "is not an attribute of polygon input"))}

  suppressMessages (

  int =  areal::aw_intersect(poly,
                              source  = grid,
                              areaVar = "area") %>%

          areal::aw_total(source = grid,
                        id       = "grid_ids",
                        areaVar  = "area",
                        totalVar = "totalArea",
                        type     = "extensive",
                        weight   = "total") %>%

          areal::aw_weight(areaVar   = "area",
                         totalVar    = "totalArea",
                          areaWeight = "areaWeight") %>%

          data.frame()
  )

  return( merge(int[, names(int) %in% c('grid_ids', abb, 'areaWeight')],
                st_set_geometry(grid[,"grid_ids"],  NULL),
                by = "grid_ids",
                all.y = T) )
}


zonal_stats1 = function(grid, poly, w){

  abb = names(w)[2]
  names(w)[1:3] = c("grid_ids", "poly_id", "w")

  if(!AOI::checkClass(poly, "sf")) {
    poly = sf::st_as_sf(poly)
  }

  w = merge(w,
            st_set_geometry(grid, NULL),
            by = "grid_ids",
            all.y = T,
            all.x = T)

  s = split(w[ , !(names(w) %in% c("poly_id", "grid_ids"))], w$poly_id)

  l = lapply(s, function(x) (colSums(x * x$w, na.rm = T) / sum(x$w))   )

  df = data.frame(poly_id = names(s), do.call(rbind, l))

  names(df) = c("poly_id", "w", names(w)[4:NCOL(w)])
  return( merge(x = poly,
                y = df,
                by.x = abb,
                by.y = 'poly_id') %>%
            st_set_crs(st_crs(st_crs(grid)))
  )
}

```
